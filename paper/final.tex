\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{times}
\usepackage{url}
\usepackage{hyperref}
\usepackage{graphicx}
\title{Evaluating BERT’s Ability to Identify Dogwhistle Expressions in Text}
\author{Alexander Pieroni, Alexandra Doss, Aakriti Bhattarai, Tochi Onuegbu, \\ Dese Elumaro, Maya Markus-Malone}
\date{}

\begin{document}
\maketitle

\begin{abstract}
Dogwhistles are pervasive in online spaces and contribute to bias in political and societal discourse; the issue of identifying such terms in NLP tasks is increasingly relevant as these textual features become more prevalent across many different texts, contexts, and datasets. Our team seeks to determine whether a Large Language Model (LLM) can be fine-tuned to identify dogwhistles both inside and outside training data. We train BERT on a robust glossary of over dogwhistles to detect and interpret potential covertly biased expressions and show that the model's sensitivity yields a high identification and false positivity rate. Our study demonstrates how the cohesion (or lack thereof) across dogwhistle and non-dogwhistle training corpora has considerable impact on the success and utility of the model.
\end{abstract}

\section{Introduction}
\subsection{Definitions and Research Question}
Dog Whistle Terms are coded expressions that convey one overt meaning to a general audience, while also signaling a covert, often hateful or provocative message to a specific in-group audience. For instance, the phrase "Actual Woman" may seem to simply refer to someone identifying as female on its surface. However, its underlying implication is a transphobic assertion that the speaker is a cisgender woman, with the insinuation that transgender women are not "real women." \\
	Our research group aims to investigate whether large language models (LLMs) like BERT can accurately detect dog whistle expressions embedded within real-world text data. Furthermore, we want to evaluate if our fine-tuned LLM can successfully identify dog whistle terms that are provided to it from a dataset. Finally, we seek to determine whether the model can generate novel dog whistle phrases itself or recognize dog whistles that are not present in the training data it was exposed to.

\section{Background}
Our model was inspired by existing Natural Language Processing models used to identify dogwhistles and hate speech in text. "Distributional Properties of Political Dogwhistle Representations in Swedish BERT"[3] analyses Swedish political dogwhistles using NLP techniques. The research involved a survey where 1000 Swedes replaced suspected dogwhistles in sentences with their interpretations. These responses, annotated for correct identification of dogwhistles, were evaluated by trained annotators. Using BERT-based sentence transformers, the study generated semantic representations of these sentences, which were then classified using K-means clustering. Results showed a clear separation between "in-group" and "out-group" responses in the semantic space, aligning with annotator judgments. This separation indicated that dogwhistle interpretations are linearly separable in vector space, demonstrating the effectiveness of advanced NLP models in identifying political dogwhistles. \\ Defersha and Tune [2] built a model for detecting hate speech in Afan Oromo texts on social platforms was developed, leveraging a Linear Sup- port Vector Classifier that achieved an F1-score of 64\% after rigorous preprocessing and feature ex- traction techniques like N-Gram and TF-IDF. The study underscored the importance of appropriate preprocessing, data annotation, and machine learn- ing algorithms in building effective hate speech detection systems. The study deployed both a BiLSTM model with domain-specific word embeddings and a BERT model, achieving F1-scores of 0.75 and 0.80, respectively. The research highlighted the effective- ness of deep learning and natural language process- ing techniques, with the BiLSTM model capitalizing on an architecture designed for sequential data and the BERT model benefiting from pretraining on large datasets and its bidirectional contextual understanding.\\
"Automatic Hate Speech Detection Using Killer Natural Language Processing Optimizing Ensemble Deep Learning Approach," [4] introduces the KNLPEDNN system, a sophisticated approach for detecting hate speech on Twitter. This system utilizes an advanced natural language processing (NLP) ensemble deep learning technique. The method involves a multi- step process: data collection from Twitter, preprocessing including stemming and tokenization, and extraction of various linguistic features like semantics, sentiment, and unigrams. These features are vectorized and processed through an ensemble deep learning classifier. The classifier is designed to identify tweets as hate speech, offensive speech, or neither, using techniques like N-gram analysis, term frequency, and inverse document frequency. With a reported accuracy of 98.71\% and minimal errors, the system effectively minimizes weak features and optimizes network weights through a gradient descent process. The KNLPEDNN system stands out for its high recall value in identifying hate speech, showcasing the potential of combining NLP and deep learning for automated content moderation on social media platforms.\\
These studies provide a foundation for developing a Bert model to identify dogwhistles by showcasing the effectiveness of advanced NLP techniques and deep learning architectures in detecting subtle linguistic cues and offensive language patterns which we built off on when constructing our model.\\



\section{Methodology}
\subsection{Data Collection}
 Our study utilizes the "Glossary of Dogwhistles" compiled by Mendelsohn et al. [1] from academic papers, media coverage, and wiki glossaries. Their paper formulates a taxonomy of dogwhistles that considers the register (informal or formal), persona (in-group identity), and type (persona signals that primarily indicate the speaker's identity or those that also change the message's meaning for those in the in-group). When testing GPT-3's success in recognizing dogwhistles based on this data, researchers found that adding a 'secret cue' and definition to the prompt that overtly associates the term with its covert meaning increases the true positive rate from 8.5\% to 54.3\%.  Our team is interested in expanding upon these findings by shifting from GPT-3 to BERT to explore how the bidirectional context processing can increase identification without adding these explicit definitions to the corpora. Accordingly, we extract the example sentences from the glossary and remove additional speaker information to avoid tokenization of unoriginal text. We also add 50 basic sentences we composed without any dogwhistles to the training data (e.g. "I'm planning a trip for next month.", "I've been feeling a bit tired lately.", etc.). After considering the ethical impacts of writing sentences that more closely resemble those present in the glossary and/or implement 'innocuous' usages of terms, we decided that providing these simple sentences was the best approach to limit the degree of added bias from the research team despite the lower comparability of the demarcated ‘dogwhistle’ vs ‘non-dogwhistle' entries in the training data. 


\subsection{Model Training}

The "Bert-eat-dog-world" initiative, on which we based our model on, aims to enhance the detection of dogwhistle expressions using a fine-tuned BERT model, leveraging the capabilities of active learning through the modAL library and seamless PyTorch integration via the skorch API. This approach allows the model to iteratively learn from the most informative samples, increasing its ability to identify subtle linguistic cues within dogwhistles. 

\subsubsection{System Architecture}
The system is structured around three main scripts: 
\begin{itemize}
    \item \textbf{activebert.py:} Hosts the ActiveBERT class, managing the active learning lifecycle using a BERT model. This class is crucial for selectively querying samples that the model finds challenging, thereby focusing learning efforts where they are most needed.
    \item \textbf{preprocessing.py:} Implements the DataLoader class, which processes input TSV files into a format suitable for the active learner, facilitating efficient data management.
    \item \textbf{main.py:} This script is responsible for the orchestration of the training process, initiating the active learner with filenames provided via command line and leveraging the DataLoader to prepare the data.
\end{itemize}

\subsubsection{Model Training Process}
\begin{itemize}
    \item \textbf{Data Transformation and Preparation:} Using the DataLoader, data from the "Glossary of Dogwhistles" is structured into a usable format. This glossary includes a range of dogwhistles along with contextual sentences that either overtly or covertly incorporate these expressions. The data is then split into training and validation sets. This separation allows for the ongoing evaluation of the model’s performance on unseen data, ensuring the model is not just memorizing the training data.
    \item \textbf{Tokenization and Input Formatting:} The BERT tokenizer is applied to the data to convert text into tokens that the model can process. This step is crucial for the model to understand the input data. Each input sequence is padded or truncated to a consistent length and equipped with an attention mask. These masks help the model focus on the relevant parts of the data, ignoring padded areas. Skorch and scikit-learn's Pipeline automate this step, ensuring efficiency and reducing manual coding requirements.
    \item \textbf{Active Learning Cycle:} The ActiveBERT class uses an uncertainty sampling strategy, where the model is initially trained on a subset of the data and then iteratively requests additional training samples that it predicts will most improve its accuracy. This method allows the model to focus on the most informative data points, refining its ability to discern between genuine and benign uses of potential dogwhistles. As the model encounters sentences that challenge its current understanding, it learns to better generalize from complex cues and subtle contexts.
    \item \textbf{Integration and Iterative Training:} The integration with skorch allows the active learning process to be embedded within a familiar scikit-learn pipeline, making it easy to apply standard machine learning workflows and optimizations. The model undergoes several cycles of training and querying, with performance metrics evaluated at each step to monitor progress and make necessary adjustments.
\end{itemize}

\subsection{Model In Action}
\subsubsection{Data Loading} The model loads a CSV file containing text samples and their corresponding labels indicating whether they contain dog whistles or not. Then, it preprocesses the data by selecting a subset of the dataset (the first 1000 samples) and splitting it into training and validation sets.
Model Initialization: The code initializes a BERT model for sequence classification (BertForSequenceClassification) and a tokenizer (BertTokenizer) with the bert-base-uncased pre-trained weights. It configures the model for binary classification by specifying num\_labels=2.
\subsubsection{Tokenization} The text data is tokenized using the tokenizer, ensuring padding and truncation to a maximum length of 512 tokens per sequence.
Data Preparation: Tokenized inputs are converted into PyTorch datasets suitable for training ($train_dataset$) and evaluation (val\_dataset).
\subsubsection{Training} The Trainer object (trainer) is invoked to start the training process. The model is first initialized with pre-trained weights from the BERT model checkpoint (bert-base-uncased). Any new weights introduced in the fine-tuning process are randomly initialized. The model is then moved to the GPU for faster training if a GPU is available (model = model.to('cuda')). For each epoch, the training data is iterated over in batches. Within each batch:
Forward Pass: The input data is passed through the model to obtain predictions.
Loss Computation: The loss between the predicted outputs and the ground truth labels is computed.
Backward Pass: The gradients of the loss with respect to the model parameters are calculated.
The optimizer then adjusts the model parameters based on the computed gradients to minimize the loss. After each epoch, the trained model is evaluated on the validation dataset. The model checkpoints are saved at regular intervals (controlled by the save\_strategy) in the specified output directory. Throughout the training process, various outputs are logged, including training loss, training time, evaluation metrics, and any other relevant information. These outputs provide the data and metrics used to evaluate the accuracy and strength of the model.

\subsection{Evaluations}
The EvalPrediction class from the transformer trainer utility library in the code to produced the evaluation metrics for our model. First, there was a low eval\_loss value, .169, where good values for the metric are between .1-1; this indicates the model has good performance during validation and testing phases. The model had an overall accuracy level of 93.7\%, with further the probability of the model being correct given it returned positive for presence of a dogwhistle as 93.75\%. The model also had a recall metric of 1: perfect recall. The F1 metric, a balance between precision and recall was 96.7\%. Further, we ran the model on specific text samples to test the percentage confidence of the presence of a dogwhistle. For example, for the sentence with a dogwhistle, “real women know the issue,” our model was 94.7\% confident that it contained a dogwhistle. But for sentences without dogwhistles, our model’s confidence of presence of dogwhistle stayed high. For the sentence, “I love you,” the model was 87.1\% confident that a dogwhistle was present. Again, for the sentence, “We are accepting of everyone,” the model reported that there was a dogwhistle present with 91.6\% confidence.

\section{Results and Conclusion}
 Reflecting on the research question we had initially hoped to answer: can large language models (LLMs), such as BERT, accurately identify dogwhistle expressions in real-world texts and can the model identify the dogwhistles provided? Yes. With an accuracy rate recall metric both above 90\%, it would seem that are model is near perfect. But, the model struggled with identifying dogwhistles outside of the given dataset and reported that there was a dogwhistle present with high confidence on sentences with an easily identifiable lack of dogwhistles. This leads us to believe that it may be better to have a narrower research question in future iterations of this research. Ways in which it can be narrowed is rather than asking if BERT can identify any dogwhistle, we could have focused on a specific dogwhistles and ways in which it’s used in different iterations between in and out groups and whether or not BERT can identify these distinctions. Our second research question was: can the model generate new dogwhistles or identify dogwhistles that are out of the test dataset? The model was able to identify dogwhistles that were out of the dataset, but with an alarmingly high rate of false positives. Again, revising the research question to ask if it could accurately identify dogwhistles outside of the dataset would provide a more accurate conclusion as to the usefulness of the model. It is suspected that the high rate of false positives is due to the training data set's limitations. Almost all of the sentences in the training data included dogwhistles, so the model was not well prepared to differentiate sentences that didn’t have dogwhistles from ones that did. In future iterations of the model, we will use a more comprehensive training dataset so that the model can better extrapolate. 
\begin{thebibliography}{9}
\bibitem{mendelsohn2023}
Julia Mendelsohn, Ronan Le Bras, Yejin Choi, and Maarten Sap. 2023. From dogwhistles to bullhorns: Unveiling coded rhetoric with language models. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics, pages 15162– 15180, University of Michigan School of Information, Allen Institute for AI, Paul G. Allen School of Computer Science Engineering University of Washington, Language Technologies Institute Carnegie Mellon University. Association for Computational Linguistics.
\bibitem{bert2}
Naol Bakala Defersha and Kula Kekeba Tune. 2021. Detection of hate speech text in afan oromo social media using machine learning approach. Indian Journal of Science and Technology, 14(31):2567–2578.
\bibitem{swedish}
Niclas Hertzberg, Asad Sayeed, Ellen Breitholtz, Robin Cooper, Elina Lindgren, Gregor Rettenegger, and Björn Rönnerstrand. 2022. Distributional properties of political dogwhistle representations in swedish bert. In Proceedings of the Sixth Workshop on Online Abuse and Harms, pages 170–175. Association for Computational Linguistics.
\bibitem{killer}
Zafer Al-Makhadmeh and Amr Tolba. 2020. Automatic hate speech detection using killer natural language processing optimizing ensemble deep learning approach. Computing, 102(501-522).
\end{thebibliography}
\end{document}
```